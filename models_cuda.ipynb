{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "## KNN\n",
    "Lets first create a K-NN model. During \"training\" it saves all dataframes in an internal storrage\n",
    "During testing, it calculates the distance between the input and all stored samples and selects the (majority vote) label of the K nearest neighbors.\n",
    "\n",
    "A good K can be found by using k-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.preprocess_data import preprocess_dataset\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    MAX_MATRIX_ENTRIES = 1e8\n",
    "    def __init__(self, num_cols : int, k : int ) -> None:\n",
    "        \"\"\"Creates an empty KNN classifier\n",
    "\n",
    "        Args:\n",
    "            num_cols (int): The number of columns (features) the data is going to have, including the label.\n",
    "            k (int): The number of neighbours that should be considered.\n",
    "        \"\"\"\n",
    "        self.data = np.empty([0,num_cols])\n",
    "        self.shape = self.data.shape\n",
    "        self.k = k\n",
    "        self.__verbose =  False\n",
    "        return\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.top_k(*args, **kwds)\n",
    "\n",
    "    def verbose(self, verbose = True) -> None:\n",
    "        \"\"\"Sets the model to the verbose mode, where it comments on what it is doing.\n",
    "\n",
    "        Args:\n",
    "            verbose (bool, optional): Defaults to True.\n",
    "        \"\"\"\n",
    "        self.__verbose = True\n",
    "        return None\n",
    "    \n",
    "    def store_data(self,df : pd.DataFrame ) -> None:\n",
    "        \"\"\"Stores a single dataframe into the internal storage\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The data to be saved.\n",
    "        \"\"\" \n",
    "        self.data = np.concatenate([self.data, df.to_numpy()])\n",
    "        self.shape = self.data.shape\n",
    "        \n",
    "        if self.__verbose:\n",
    "            print(\"New shape is {}.\".format(self.shape))\n",
    "        # Reset internal\n",
    "        self.__dat = None\n",
    "        self.__lab = None\n",
    "        return\n",
    "    \n",
    "    def set_k(self,k:int) -> None:\n",
    "        \"\"\"Set another k hyperparameter\n",
    "\n",
    "        Args:\n",
    "            k (int): The new k\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "    \n",
    "    def top_k(self, datapoint : np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculates the label using the cosine similarity between each datapoint and the stored data points\n",
    "\n",
    "        Args:\n",
    "            datapoint (np.narray): An array of shape [N,C], where N is the number of datasamples (rows) and C the number of features (columns), not including the label\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: An array of shape [N], containing the label prediction \n",
    "        \"\"\"\n",
    "        assert datapoint.shape[1] == self.shape[1]-1\n",
    "        \n",
    "        datapoint = datapoint.copy()\n",
    "        \n",
    "        # Pepare internal data representation for calculation\n",
    "        if self.__dat == None:\n",
    "            \n",
    "            # Remove label column\n",
    "            self.__dat = self.data[:,:-1].astype(np.float16)\n",
    "            self.__lab = self.data[:,-1].astype(int)\n",
    "            \n",
    "            # Normalize each row to length 1\n",
    "            self.__dat = self.__dat  / np.linalg.norm(self.__dat, axis = 1, keepdims=True)\n",
    "            self.__dat = torch.t(torch.from_numpy(self.__dat)).to(device)\n",
    "\n",
    "        datapoint = torch.from_numpy(datapoint  / np.linalg.norm(datapoint, axis = 1, keepdims=True)).to(device)\n",
    "        \n",
    "        # Split input array into smaller ones if N*n is to big\n",
    "        step_size = max(1,int(KNN.MAX_MATRIX_ENTRIES // len(self)))\n",
    "        labels_accumulator = []\n",
    "        \n",
    "        max_i = math.ceil(len(datapoint)/ step_size)\n",
    "        \n",
    "        if self.__verbose:\n",
    "            print(\"Starts calculating on self.data ({}) and input ({}).\".format(self.shape, datapoint.shape))\n",
    "            _st_t = datetime.datetime.now()\n",
    "    \n",
    "        for i in range(max_i):\n",
    "            if self.__verbose:\n",
    "                _en_t = datetime.datetime.now()\n",
    "                _t = _en_t - _st_t\n",
    "                if i == 0:\n",
    "                     _t_ex = datetime.timedelta(seconds = 0)\n",
    "                else:\n",
    "                    _t_ex = _t *(max_i/i)\n",
    "\n",
    "            \n",
    "                print(\"Finsihed datapoints {}/{} ({}/{})    {}m{}s/{}m{}s\".format(\n",
    "                    i * step_size, len(datapoint), \n",
    "                    i,max_i,\n",
    "                    _t.seconds//60, _t.seconds%60,\n",
    "                    _t_ex.seconds//60, _t_ex.seconds%60,\n",
    "                    ),\n",
    "                      end = \"\\r\")\n",
    "            # Calculate dot product of matrices\n",
    "            cos_sim = torch.mm(datapoint[i*step_size:(i+1)*step_size] , self.__dat) #N*n\n",
    "            \n",
    "            # Get indices of highest value\n",
    "            _ , ind = torch.topk(cos_sim, self.k, dim = 1, largest = True, sorted = False)\n",
    "            ind = ind.cpu()\n",
    "            # Get corresponding labels from internal data\n",
    "            labels = np.array([self.__lab[ind[i]] for i in range(len(ind))])     \n",
    "        \n",
    "            # Do majority vote for each input data point\n",
    "            labels = np.array([np.argmax(np.bincount(labels[i])) for i in range(len(labels))])\n",
    "\n",
    "            labels_accumulator.append(labels)\n",
    "        \n",
    "\n",
    "        return np.concatenate(labels_accumulator)\n",
    "        \n",
    "\n",
    "def calculate_accuraccy(labels1 : np.ndarray, labels2 : np.ndarray) -> float:\n",
    "    \"\"\"Calculates the accuraccy of a prediction in refference to the ground-truth\n",
    "\n",
    "    Args:\n",
    "        labels1 (np.ndarray): Ground-truth or prediction of shape [N]\n",
    "        labels2 (np.ndarray): Ground-truth or prediction of shape [N]\n",
    "\n",
    "    Returns:\n",
    "        float: The accuraccy of the prediction\n",
    "    \"\"\"\n",
    "    assert labels1.shape == labels2.shape\n",
    "    \n",
    "    diff = labels1 - labels2\n",
    "    wrong = np.count_nonzero(diff)\n",
    "    correct = len(labels1) - wrong\n",
    "    \n",
    "    return correct/len(labels1) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished p1_d1. Took 0 minutes, 20 seconds\n",
      "Finished p1_d2. Took 0 minutes, 20 seconds\n",
      "Finished p2_d1. Took 0 minutes, 21 seconds\n",
      "Finished p2_d2. Took 0 minutes, 22 seconds\n"
     ]
    }
   ],
   "source": [
    "dfs = preprocess_dataset(\"condensed\", 10, False,persons=[1,2], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420758, 17)\n",
      "(857298, 17)\n",
      "(1273277, 17)\n",
      "(1720523, 17)\n",
      "Training completed\n",
      "\n",
      "\n",
      "Start testing\n",
      "Accuracy was 90.0\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(len(dfs[list(dfs.keys())[0]].columns), 5)\n",
    "knn.shape\n",
    "for k in dfs.keys():\n",
    "    knn.store_data(dfs[k])\n",
    "    print(knn.shape)\n",
    "print(\"Training completed\")  \n",
    "\n",
    "sample_length = 10\n",
    "dp = dfs[\"p1_d1\"].to_numpy()[:sample_length,:-1]\n",
    "\n",
    "print(\"\\n\\nStart testing\")\n",
    "y = knn(dp)    \n",
    "print(\"Accuracy was {}\".format(calculate_accuraccy(y,dfs[\"p1_d1\"].to_numpy()[:sample_length,-1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze performance\n",
    "Show how good we can predict one day by the previous day per person\n",
    "\n",
    "Problems: It takes too long because data is too high-dimensional $~(|4e5| \\cdot |4e5|) = ~ 10^{11}$ matrix values that have to be computed\n",
    "\n",
    "Ideas to improve performance:\n",
    "- Use tensors on GPU\n",
    "\n",
    "Ideas to reduce dimensionality: \n",
    "- 1. Make bigger time windows (Reduce rows)\n",
    "- 2. Use PCA on stored data and input data (Reduce columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished p1_d1. Took 0 minutes, 18 seconds\n",
      "Finished p1_d2. Took 0 minutes, 16 seconds\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "dfs = preprocess_dataset(\"condensed\", 10, False, persons=list(range(1,P+1,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape is (420758, 17).\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 25.7 MiB for an array with shape (420758, 16) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Uni\\Neurocognitive Computing\\Neurocog\\models_cuda.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m knn\u001b[39m.\u001b[39mverbose()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m knn\u001b[39m.\u001b[39mstore_data(dfs[\u001b[39m\"\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_d1\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p)])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m pred \u001b[39m=\u001b[39m knn(df\u001b[39m.\u001b[39;49mto_numpy()[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m acc \u001b[39m=\u001b[39m calculate_accuraccy(pred, df\u001b[39m.\u001b[39mto_numpy()[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuraccy for p = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p,acc))\n",
      "\u001b[1;32md:\\Uni\\Neurocognitive Computing\\Neurocog\\models_cuda.ipynb Cell 8\u001b[0m in \u001b[0;36mKNN.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_k(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;32md:\\Uni\\Neurocognitive Computing\\Neurocog\\models_cuda.ipynb Cell 8\u001b[0m in \u001b[0;36mKNN.top_k\u001b[1;34m(self, datapoint)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Pepare internal data representation for calculation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__dat \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39m# Remove label column\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__dat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__lab \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Uni/Neurocognitive%20Computing/Neurocog/models_cuda.ipynb#X10sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39m# Normalize each row to length 1\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 25.7 MiB for an array with shape (420758, 16) and data type float32"
     ]
    }
   ],
   "source": [
    "ov_acc = 0\n",
    "K = 5\n",
    "\n",
    "for p in range(1,P+1,1):\n",
    "    df = dfs[\"p{}_d2\".format(p)]\n",
    "    knn = KNN(len(df.columns), K)\n",
    "    \n",
    "    knn.verbose()\n",
    "    \n",
    "    knn.store_data(dfs[\"p{}_d1\".format(p)])\n",
    "    \n",
    "    pred = knn(df.to_numpy()[:,:-1])\n",
    "    acc = calculate_accuraccy(pred, df.to_numpy()[:,-1] )\n",
    "    \n",
    "    print(\"Accuraccy for p = {} is {:.2f}\".format(p,acc))\n",
    "    ov_acc += acc\n",
    "    \n",
    "print(\"\\nOverall accuraccy in predicting the second day was {}\".format(ov_acc/10))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9df5590c36242588aa2ec08b48d5460772f3434d8fd6d76e09f7949a0a7cd2ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
