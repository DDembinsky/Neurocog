{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "## KNN\n",
    "Lets first create a K-NN model. During \"training\" it saves all dataframes in an internal storrage\n",
    "During testing, it calculates the distance between the input and all stored samples and selects the (majority vote) label of the K nearest neighbors.\n",
    "\n",
    "A good K can be found by using k-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.preprocess_data import preprocess_dataset, pca_dataset, balance_class_distribution\n",
    "import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import deque\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.5\n",
      "(array([50., 50., 75.]), array([100.,  50.,  60.]))\n"
     ]
    }
   ],
   "source": [
    "class KNN():\n",
    "    MAX_MATRIX_ENTRIES = 2e8\n",
    "\n",
    "    def __init__(self, num_cols: int, k: int) -> None:\n",
    "        \"\"\"Creates an empty KNN classifier\n",
    "\n",
    "        Args:\n",
    "            num_cols (int): The number of columns (features) the data is going to have, including the label.\n",
    "            k (int): The number of neighbours that should be considered.\n",
    "        \"\"\"\n",
    "        self.data = np.empty([0, num_cols])\n",
    "        self.shape = self.data.shape\n",
    "        self.k = k\n",
    "        self.__verbose = False\n",
    "        self.use_dims = None\n",
    "        self.__pc = None\n",
    "        return\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.top_k(*args, **kwds)\n",
    "\n",
    "    def verbose(self, verbose=True) -> None:\n",
    "        \"\"\"Sets the model to the verbose mode, where it comments on what it is doing.\n",
    "\n",
    "        Args:\n",
    "            verbose (bool, optional): Defaults to True.\n",
    "        \"\"\"\n",
    "        self.__verbose = True\n",
    "        return None\n",
    "\n",
    "    def set_reduce_dimensions(self, num_leading_dim: int) -> None:\n",
    "        \"\"\"Sets KNN to use PCA in order to reduce the dimensionality of the data.\n",
    "\n",
    "        Args:\n",
    "            num_leading_dim (int): The number of PCs that should be used for the trasnformation.\n",
    "        \"\"\"\n",
    "        self.use_dims = num_leading_dim\n",
    "        return\n",
    "\n",
    "    def get_pca(self):\n",
    "        if self.use_dims is None:\n",
    "            raise Exception(\"PCA can only be performed after setting a number of dimensions for reduction. Use ```KNN.set_reduce_dimensions```\")\n",
    "        if self.__pc is None:\n",
    "            self.__pca(None)\n",
    "        return self.__pc.components_\n",
    "    \n",
    "    def store_data(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Stores a single dataframe into the internal storage\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The data to be saved.\n",
    "        \"\"\"\n",
    "        self.data = np.concatenate([self.data, df.to_numpy()])\n",
    "        self.shape = self.data.shape\n",
    "\n",
    "        if self.__verbose:\n",
    "            print(\"New shape is {}.\".format(self.shape))\n",
    "        # Reset internal\n",
    "        self.__dat = None\n",
    "        self.__lab = None\n",
    "        self.__pc = None\n",
    "        return\n",
    "\n",
    "    def set_k(self, k: int) -> None:\n",
    "        \"\"\"Set another k hyperparameter\n",
    "\n",
    "        Args:\n",
    "            k (int): The new k\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "\n",
    "    def __pca(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Performs PCA on the internal saved data to calculate the transformed data\"\"\"\n",
    "        # Check if saved PCs are available\n",
    "        \n",
    "        if self.__pc is None:\n",
    "            # Calculate PCs\n",
    "            self.__pc = PCA(n_components = self.use_dims).fit(self.data[:,:-1])\n",
    "            \n",
    "            self.data = np.concatenate([self.__pc.transform(self.data[:,:-1]), self.data[:,-1, None] ], axis = 1)\n",
    "            self.shape = self.data.shape\n",
    "            \n",
    "        if data is None:\n",
    "            return   \n",
    "        \n",
    "        # Transform data\n",
    "        data = self.__pc.transform(data)\n",
    "    \n",
    "        return data\n",
    "\n",
    "    def top_k(self, datapoint: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculates the label using the cosine similarity between each datapoint and the stored data points\n",
    "\n",
    "        Args:\n",
    "            datapoint (np.narray): An array of shape [N,C], where N is the number of datasamples (rows) and C the number of features (columns), not including the label\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: An array of shape [N], containing the label prediction \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        datapoint = datapoint.copy()\n",
    "\n",
    "        if self.use_dims is not None:\n",
    "            datapoint = self.__pca(datapoint)\n",
    "        \n",
    "        assert datapoint.shape[1] == self.shape[1]-1\n",
    "        \n",
    "        \n",
    "        # Pepare internal data representation for calculation\n",
    "        if self.__dat == None:\n",
    "\n",
    "            # Remove label column\n",
    "            self.__dat = self.data[:, :-1]\n",
    "            self.__lab = self.data[:, -1].astype(int)\n",
    "\n",
    "            # Normalize each row to length 1\n",
    "            self.__dat = self.__dat / \\\n",
    "                np.linalg.norm(self.__dat, axis=1, keepdims=True)\n",
    "\n",
    "        datapoint = datapoint / \\\n",
    "            np.linalg.norm(datapoint, axis=1, keepdims=True)\n",
    "\n",
    "        # Split input array into smaller ones if N*n is to big\n",
    "        step_size = max(1, int(KNN.MAX_MATRIX_ENTRIES // len(self)))\n",
    "        labels_accumulator = []\n",
    "\n",
    "        max_i = math.ceil(len(datapoint) / step_size)\n",
    "\n",
    "        if self.__verbose:\n",
    "            print(\"Starts calculating on self.data ({}) and input ({}).\".format(\n",
    "                self.shape, datapoint.shape))\n",
    "            _st_t = datetime.datetime.now()\n",
    "\n",
    "        for i in range(max_i):\n",
    "\n",
    "            if self.__verbose:\n",
    "                _en_t = datetime.datetime.now()\n",
    "                _t = _en_t - _st_t\n",
    "                if i == 0:\n",
    "                    _t_ex = datetime.timedelta(seconds=0)\n",
    "                else:\n",
    "                    _t_ex = _t * (max_i/i)\n",
    "\n",
    "                print(\"Finsihed datapoints {}/{} ({}/{})    {}m{}s/{}m{}s\".format(\n",
    "                    i * step_size, len(datapoint),\n",
    "                    i, max_i,\n",
    "                    _t.seconds//60, _t.seconds % 60,\n",
    "                    _t_ex.seconds//60, _t_ex.seconds % 60,\n",
    "                ),\n",
    "                    end=\"\\r\")\n",
    "\n",
    "            # Calculate dot product of matrices\n",
    "            cos_sim = datapoint[i*step_size:(i+1)*step_size] @ self.__dat.T\n",
    "\n",
    "            # Get indices of highest value\n",
    "            ind = np.argpartition(cos_sim, -self.k, axis=1)[:, -self.k:]\n",
    "\n",
    "            # Get corresponding labels from internal data\n",
    "            labels = np.array([self.__lab[ind[i]] for i in range(len(ind))])\n",
    "\n",
    "            # Do majority vote for each input data point\n",
    "            labels = np.array([np.argmax(np.bincount(labels[i]))\n",
    "                              for i in range(len(labels))])\n",
    "\n",
    "            labels_accumulator.append(labels)\n",
    "\n",
    "        if self.__verbose:\n",
    "            _en_t = datetime.datetime.now()\n",
    "            _t = _en_t - _st_t\n",
    "            _t_ex = _t\n",
    "\n",
    "            print(\"Finsihed datapoints {}/{} ({}/{})    {}m{}s/{}m{}s\".format(\n",
    "                len(datapoint), len(datapoint),\n",
    "                max_i, max_i,\n",
    "                _t.seconds//60, _t.seconds % 60,\n",
    "                _t_ex.seconds//60, _t_ex.seconds % 60,\n",
    "            ),)\n",
    "\n",
    "        return np.concatenate(labels_accumulator)\n",
    "\n",
    "\n",
    "def calculate_accuraccy(true: np.ndarray, pred: np.ndarray) ->  float:\n",
    "    \"\"\"Calculates the accuraccy of a prediction in refference to the ground-truth\n",
    "\n",
    "    Args:\n",
    "        true (np.ndarray): Ground-truth of shape [N]\n",
    "        pred (np.ndarray): Prediction of shape [N]\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy over all datasamples\n",
    "    \"\"\"\n",
    "    assert true.shape == pred.shape\n",
    "\n",
    "    p = true-pred\n",
    "    wrong = np.count_nonzero(p)\n",
    "    correct = len(true) - wrong\n",
    "\n",
    "    return correct/len(true)* 100\n",
    "\n",
    "def precission_recall(true: np.ndarray, pred: np.ndarray) ->  tuple:\n",
    "    \"\"\"Calculates the accuraccy of a prediction in refference to the ground-truth per class\n",
    "\n",
    "    Args:\n",
    "        true (np.ndarray): Ground-truth of shape [N]\n",
    "        pred (np.ndarray): Prediction of shape [N]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: precission and recall\n",
    "    \"\"\"\n",
    "    \n",
    "    precission = precision_score(true,pred, average = None)\n",
    "    recall =        recall_score(true,pred, average = None)\n",
    "\n",
    "    return (precission * 100,recall * 100)\n",
    "\n",
    "\n",
    "print(calculate_accuraccy(\n",
    "    np.array([0,1,1,2,2,2,2,2]),\n",
    "    np.array([0,1,2,1,2,2,2,0])\n",
    "      ))\n",
    "print(precission_recall(\n",
    "    np.array([0,1,1,2,2,2,2,2]),\n",
    "    np.array([0,1,2,1,2,2,2,0])\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    dfs = preprocess_dataset(\"condensed\", 10, False, persons=[1, 2], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    knn = KNN(len(dfs[list(dfs.keys())[0]].columns), 5)\n",
    "    knn.shape\n",
    "    for k in dfs.keys():\n",
    "        knn.store_data(dfs[k])\n",
    "        print(knn.shape)\n",
    "    print(\"Training completed\")\n",
    "    \n",
    "    \n",
    "    dp = dfs[\"p1_d1\"].to_numpy()[:1000,]\n",
    "\n",
    "    knn.set_reduce_dimensions(5)\n",
    "    knn.get_pca()\n",
    "    \n",
    "    knn.verbose()\n",
    "    \n",
    "    print(\"\\n\\nStart testing\")\n",
    "    y = knn(dp[:,:-1])\n",
    "    print(\"Accuracy {}  Recall {}\".format(*calculate_accuraccy(\n",
    "        y, dp[:, -1])))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze performance\n",
    "Show how good we can predict one day by the previous day per person\n",
    "\n",
    "Problems: It takes too long because data is too high-dimensional $~(|4e5| \\cdot |4e5|) = ~ 10^{11}$ matrix values that have to be computed\n",
    "\n",
    "Ideas to improve performance:\n",
    "- Use tensors on GPU → Not practicable with current memory usage\n",
    "\n",
    "Ideas to reduce dimensionality: \n",
    "- 1. Make bigger time windows (Reduce rows) → From 10 (= 0.1s) to 3000 (=30s) \"Reason: Non reading can also have short glimpses of reading. Like in original study\"\n",
    "- 2. Use PCA on stored data and input data (Reduce columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    dfs = preprocess_dataset(\n",
    "    \"condensed\", 3000, overlapping=False, persons=list(range(1, 11, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_acc_for_k(_dfs, k):\n",
    "    ov_acc = []\n",
    "\n",
    "    for p in range(1,11, 1):\n",
    "        df = _dfs[\"p{}_d2\".format(p)]\n",
    "        knn = KNN(len(df.columns), k)\n",
    "        # print(\"\")\n",
    "        # knn.verbose()\n",
    "\n",
    "        knn.store_data(_dfs[\"p{}_d1\".format(p)])\n",
    "\n",
    "        pred = knn(balance_class_distribution(df.to_numpy()[:, :-1]))\n",
    "        acc = calculate_accuraccy(pred, df.to_numpy()[:, -1])\n",
    "\n",
    "        #print(\"Accuraccy for p = {} is {:.2f}\".format(p,acc))\n",
    "        ov_acc.append(acc)\n",
    "\n",
    "\n",
    "    print(\"\\nOverall accuraccy in predicting the second day was {:.2f}({:.2f}) for K = {}\".format(\n",
    "        np.mean(ov_acc), np.std(ov_acc), k))\n",
    "    \n",
    "    return ov_acc\n",
    "\n",
    "\n",
    "def log_and_plot_KNN(_dfs, name):\n",
    "    log = pd.DataFrame()\n",
    "    for K in [1, 2, 3, 5, 7, 10, 15]:\n",
    "        acc = overall_acc_for_k(_dfs, K)\n",
    "        \n",
    "        log = pd.concat([log, pd.DataFrame({\n",
    "            \"K\" : [str(K) for _ in range(len(acc))], \"acc\" : acc\n",
    "        })])\n",
    "        \n",
    "    sns.boxplot(data=log, x=\"acc\", y=\"K\")\n",
    "\n",
    "    sns.despine(trim = True)\n",
    "\n",
    "    plt.grid(axis = \"x\", alpha = 0.6)\n",
    "    plt.savefig(\"res/{}.png\".format(name))\n",
    "    plt.savefig(\"res/{}.pdf\".format(name))\n",
    "    plt.close()\n",
    "    return log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all k the accuraccy in predicting day 2 from day 1 per person is around 58% for $1<k\\leq15$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished p1_d1. Took 0 minutes, 38 seconds\n",
      "Finished p1_d2. Took 0 minutes, 47 seconds\n",
      "Finished p2_d1. Took 0 minutes, 38 seconds\n",
      "Finished p2_d2. Took 0 minutes, 32 seconds\n",
      "Finished p3_d1. Took 0 minutes, 24 seconds\n",
      "Finished p3_d2. Took 0 minutes, 24 seconds\n",
      "Finished p4_d1. Took 0 minutes, 30 seconds\n",
      "Finished p4_d2. Took 0 minutes, 30 seconds\n",
      "Finished p5_d1. Took 0 minutes, 24 seconds\n",
      "Finished p5_d2. Took 0 minutes, 13 seconds\n",
      "Finished p6_d1. Took 0 minutes, 18 seconds\n",
      "Finished p6_d2. Took 0 minutes, 18 seconds\n",
      "Finished p7_d1. Took 0 minutes, 13 seconds\n",
      "Finished p7_d2. Took 0 minutes, 14 seconds\n",
      "Finished p8_d1. Took 0 minutes, 24 seconds\n",
      "Finished p8_d2. Took 0 minutes, 27 seconds\n",
      "Finished p9_d1. Took 0 minutes, 23 seconds\n",
      "Finished p9_d2. Took 0 minutes, 12 seconds\n",
      "Finished p10_d1. Took 0 minutes, 19 seconds\n",
      "Finished p10_d2. Took 0 minutes, 17 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 44.85(8.47) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 49.85(7.71) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.13(8.05) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.80(7.84) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.16(8.09) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 49.24(8.07) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 49.63(8.33) for K = 15\n",
      "Finished p1_d1. Took 0 minutes, 16 seconds\n",
      "Finished p1_d2. Took 0 minutes, 15 seconds\n",
      "Finished p2_d1. Took 0 minutes, 15 seconds\n",
      "Finished p2_d2. Took 0 minutes, 16 seconds\n",
      "Finished p3_d1. Took 0 minutes, 15 seconds\n",
      "Finished p3_d2. Took 0 minutes, 14 seconds\n",
      "Finished p4_d1. Took 0 minutes, 15 seconds\n",
      "Finished p4_d2. Took 0 minutes, 16 seconds\n",
      "Finished p5_d1. Took 0 minutes, 14 seconds\n",
      "Finished p5_d2. Took 0 minutes, 10 seconds\n",
      "Finished p6_d1. Took 0 minutes, 15 seconds\n",
      "Finished p6_d2. Took 0 minutes, 13 seconds\n",
      "Finished p7_d1. Took 0 minutes, 10 seconds\n",
      "Finished p7_d2. Took 0 minutes, 11 seconds\n",
      "Finished p8_d1. Took 0 minutes, 19 seconds\n",
      "Finished p8_d2. Took 0 minutes, 21 seconds\n",
      "Finished p9_d1. Took 0 minutes, 17 seconds\n",
      "Finished p9_d2. Took 0 minutes, 11 seconds\n",
      "Finished p10_d1. Took 0 minutes, 17 seconds\n",
      "Finished p10_d2. Took 0 minutes, 16 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 44.25(8.49) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 49.77(7.80) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.00(8.29) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.48(8.44) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.59(8.73) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.43(8.74) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.52(8.92) for K = 15\n",
      "Finished p1_d1. Took 0 minutes, 18 seconds\n",
      "Finished p1_d2. Took 0 minutes, 19 seconds\n",
      "Finished p2_d1. Took 0 minutes, 19 seconds\n",
      "Finished p2_d2. Took 0 minutes, 22 seconds\n",
      "Finished p3_d1. Took 0 minutes, 23 seconds\n",
      "Finished p3_d2. Took 0 minutes, 18 seconds\n",
      "Finished p4_d1. Took 0 minutes, 19 seconds\n",
      "Finished p4_d2. Took 0 minutes, 24 seconds\n",
      "Finished p5_d1. Took 0 minutes, 17 seconds\n",
      "Finished p5_d2. Took 0 minutes, 14 seconds\n",
      "Finished p6_d1. Took 0 minutes, 15 seconds\n",
      "Finished p6_d2. Took 0 minutes, 20 seconds\n",
      "Finished p7_d1. Took 0 minutes, 13 seconds\n",
      "Finished p7_d2. Took 0 minutes, 14 seconds\n",
      "Finished p8_d1. Took 0 minutes, 19 seconds\n",
      "Finished p8_d2. Took 0 minutes, 19 seconds\n",
      "Finished p9_d1. Took 0 minutes, 20 seconds\n",
      "Finished p9_d2. Took 0 minutes, 12 seconds\n",
      "Finished p10_d1. Took 0 minutes, 20 seconds\n",
      "Finished p10_d2. Took 0 minutes, 21 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 45.78(8.45) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 55.50(7.78) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 52.77(7.52) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 53.53(8.08) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 53.74(8.42) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 54.66(8.39) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 54.65(8.40) for K = 15\n",
      "Finished p1_d1. Took 0 minutes, 18 seconds\n",
      "Finished p1_d2. Took 0 minutes, 21 seconds\n",
      "Finished p2_d1. Took 0 minutes, 18 seconds\n",
      "Finished p2_d2. Took 0 minutes, 20 seconds\n",
      "Finished p3_d1. Took 0 minutes, 25 seconds\n",
      "Finished p3_d2. Took 0 minutes, 26 seconds\n",
      "Finished p4_d1. Took 0 minutes, 20 seconds\n",
      "Finished p4_d2. Took 0 minutes, 19 seconds\n",
      "Finished p5_d1. Took 0 minutes, 19 seconds\n",
      "Finished p5_d2. Took 0 minutes, 14 seconds\n",
      "Finished p6_d1. Took 0 minutes, 16 seconds\n",
      "Finished p6_d2. Took 0 minutes, 17 seconds\n",
      "Finished p7_d1. Took 0 minutes, 12 seconds\n",
      "Finished p7_d2. Took 0 minutes, 13 seconds\n",
      "Finished p8_d1. Took 0 minutes, 17 seconds\n",
      "Finished p8_d2. Took 0 minutes, 17 seconds\n",
      "Finished p9_d1. Took 0 minutes, 16 seconds\n",
      "Finished p9_d2. Took 0 minutes, 10 seconds\n",
      "Finished p10_d1. Took 0 minutes, 16 seconds\n",
      "Finished p10_d2. Took 0 minutes, 16 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.08(7.16) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 52.81(6.90) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 50.23(7.21) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 50.65(7.35) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 51.00(7.48) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 51.70(7.39) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 51.80(7.47) for K = 15\n",
      "Finished p1_d1. Took 0 minutes, 17 seconds\n",
      "Finished p1_d2. Took 0 minutes, 17 seconds\n",
      "Finished p2_d1. Took 0 minutes, 14 seconds\n",
      "Finished p2_d2. Took 0 minutes, 17 seconds\n",
      "Finished p3_d1. Took 0 minutes, 16 seconds\n",
      "Finished p3_d2. Took 0 minutes, 16 seconds\n",
      "Finished p4_d1. Took 0 minutes, 16 seconds\n",
      "Finished p4_d2. Took 0 minutes, 17 seconds\n",
      "Finished p5_d1. Took 0 minutes, 15 seconds\n",
      "Finished p5_d2. Took 0 minutes, 12 seconds\n",
      "Finished p6_d1. Took 0 minutes, 17 seconds\n",
      "Finished p6_d2. Took 0 minutes, 14 seconds\n",
      "Finished p7_d1. Took 0 minutes, 10 seconds\n",
      "Finished p7_d2. Took 0 minutes, 12 seconds\n",
      "Finished p8_d1. Took 0 minutes, 20 seconds\n",
      "Finished p8_d2. Took 0 minutes, 18 seconds\n",
      "Finished p9_d1. Took 0 minutes, 19 seconds\n",
      "Finished p9_d2. Took 0 minutes, 10 seconds\n",
      "Finished p10_d1. Took 0 minutes, 19 seconds\n",
      "Finished p10_d2. Took 0 minutes, 17 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 44.69(7.29) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 49.49(6.55) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 46.53(6.78) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.20(6.41) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.67(6.22) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.50(6.09) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.32(6.27) for K = 15\n",
      "Finished p1_d1. Took 0 minutes, 13 seconds\n",
      "Finished p1_d2. Took 0 minutes, 14 seconds\n",
      "Finished p2_d1. Took 0 minutes, 13 seconds\n",
      "Finished p2_d2. Took 0 minutes, 18 seconds\n",
      "Finished p3_d1. Took 0 minutes, 20 seconds\n",
      "Finished p3_d2. Took 0 minutes, 13 seconds\n",
      "Finished p4_d1. Took 0 minutes, 14 seconds\n",
      "Finished p4_d2. Took 0 minutes, 16 seconds\n",
      "Finished p5_d1. Took 0 minutes, 15 seconds\n",
      "Finished p5_d2. Took 0 minutes, 10 seconds\n",
      "Finished p6_d1. Took 0 minutes, 12 seconds\n",
      "Finished p6_d2. Took 0 minutes, 14 seconds\n",
      "Finished p7_d1. Took 0 minutes, 9 seconds\n",
      "Finished p7_d2. Took 0 minutes, 12 seconds\n",
      "Finished p8_d1. Took 0 minutes, 15 seconds\n",
      "Finished p8_d2. Took 0 minutes, 15 seconds\n",
      "Finished p9_d1. Took 0 minutes, 16 seconds\n",
      "Finished p9_d2. Took 0 minutes, 11 seconds\n",
      "Finished p10_d1. Took 0 minutes, 15 seconds\n",
      "Finished p10_d2. Took 0 minutes, 14 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 44.93(8.62) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 53.96(8.12) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 51.60(8.22) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 52.16(8.71) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 52.95(8.68) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 53.87(8.56) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 54.35(8.72) for K = 15\n",
      "Finished p1_d1. Took 0 minutes, 15 seconds\n",
      "Finished p1_d2. Took 0 minutes, 17 seconds\n",
      "Finished p2_d1. Took 0 minutes, 16 seconds\n",
      "Finished p2_d2. Took 0 minutes, 16 seconds\n",
      "Finished p3_d1. Took 0 minutes, 13 seconds\n",
      "Finished p3_d2. Took 0 minutes, 12 seconds\n",
      "Finished p4_d1. Took 0 minutes, 13 seconds\n",
      "Finished p4_d2. Took 0 minutes, 14 seconds\n",
      "Finished p5_d1. Took 0 minutes, 12 seconds\n",
      "Finished p5_d2. Took 0 minutes, 9 seconds\n",
      "Finished p6_d1. Took 0 minutes, 11 seconds\n",
      "Finished p6_d2. Took 0 minutes, 12 seconds\n",
      "Finished p7_d1. Took 0 minutes, 8 seconds\n",
      "Finished p7_d2. Took 0 minutes, 9 seconds\n",
      "Finished p8_d1. Took 0 minutes, 13 seconds\n",
      "Finished p8_d2. Took 0 minutes, 13 seconds\n",
      "Finished p9_d1. Took 0 minutes, 14 seconds\n",
      "Finished p9_d2. Took 0 minutes, 8 seconds\n",
      "Finished p10_d1. Took 0 minutes, 18 seconds\n",
      "Finished p10_d2. Took 0 minutes, 18 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 42.72(7.07) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.98(6.48) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 45.80(6.72) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 46.24(6.46) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 46.20(6.72) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 46.72(6.45) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 46.86(6.19) for K = 15\n",
      "Finished p1_d1. Took 0 minutes, 14 seconds\n",
      "Finished p1_d2. Took 0 minutes, 20 seconds\n",
      "Finished p2_d1. Took 0 minutes, 16 seconds\n",
      "Finished p2_d2. Took 0 minutes, 16 seconds\n",
      "Finished p3_d1. Took 0 minutes, 32 seconds\n",
      "Finished p3_d2. Took 0 minutes, 24 seconds\n",
      "Finished p4_d1. Took 0 minutes, 20 seconds\n",
      "Finished p4_d2. Took 0 minutes, 20 seconds\n",
      "Finished p5_d1. Took 0 minutes, 34 seconds\n",
      "Finished p5_d2. Took 0 minutes, 11 seconds\n",
      "Finished p6_d1. Took 0 minutes, 14 seconds\n",
      "Finished p6_d2. Took 0 minutes, 12 seconds\n",
      "Finished p7_d1. Took 0 minutes, 9 seconds\n",
      "Finished p7_d2. Took 0 minutes, 11 seconds\n",
      "Finished p8_d1. Took 0 minutes, 19 seconds\n",
      "Finished p8_d2. Took 0 minutes, 29 seconds\n",
      "Finished p9_d1. Took 0 minutes, 19 seconds\n",
      "Finished p9_d2. Took 0 minutes, 10 seconds\n",
      "Finished p10_d1. Took 0 minutes, 13 seconds\n",
      "Finished p10_d2. Took 0 minutes, 13 seconds\n",
      "\n",
      "Overall accuraccy in predicting the second day was 45.07(7.78) for K = 1\n",
      "\n",
      "Overall accuraccy in predicting the second day was 50.33(7.41) for K = 2\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.53(7.54) for K = 3\n",
      "\n",
      "Overall accuraccy in predicting the second day was 47.94(7.30) for K = 5\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.29(7.16) for K = 7\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.90(7.08) for K = 10\n",
      "\n",
      "Overall accuraccy in predicting the second day was 48.98(6.96) for K = 15\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    log = log_and_plot_KNN(_dfs = preprocess_dataset(\n",
    "    \"condensed\",normalize= True),\n",
    "                name=\"KNN_norm\")\n",
    "\n",
    "    log = log_and_plot_KNN(_dfs = preprocess_dataset(\n",
    "        \"condensed\", normalize= False),\n",
    "                    name=\"KNN_raw\")\n",
    "\n",
    "    log = log_and_plot_KNN(_dfs = pca_dataset(\n",
    "        preprocess_dataset(\n",
    "        \"condensed\", normalize= True), num_pc=2),\n",
    "                    name=\"KNN_norm_pca2\")\n",
    "    log = log_and_plot_KNN(_dfs = pca_dataset(\n",
    "        preprocess_dataset(\n",
    "        \"condensed\", normalize= True), num_pc=5),\n",
    "                    name=\"KNN_norm_pca5\")\n",
    "    log = log_and_plot_KNN(_dfs = pca_dataset(\n",
    "        preprocess_dataset(\n",
    "        \"condensed\",normalize= True), num_pc=10),\n",
    "                    name=\"KNN_norm_pca10\")\n",
    "\n",
    "    log = log_and_plot_KNN(_dfs = pca_dataset(\n",
    "        preprocess_dataset(\n",
    "        \"condensed\", normalize= False), num_pc=2),\n",
    "                    name=\"KNN_raw_pca2\")\n",
    "    log = log_and_plot_KNN(_dfs = pca_dataset(\n",
    "        preprocess_dataset(\n",
    "        \"condensed\", normalize= False), num_pc=5),\n",
    "                    name=\"KNN_raw_pca5\")\n",
    "    log = log_and_plot_KNN(_dfs = pca_dataset(\n",
    "        preprocess_dataset(\n",
    "        \"condensed\", normalize= False), num_pc=10),\n",
    "                    name=\"KNN_raw_pca10\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Normalized** | **PCA** | **Best Acc**   | K        |\n",
    "|----------------|---------|----------------|----------|\n",
    "|        +       | None    | 58             | 7/**10**/15  |\n",
    "|        +       | 2       | 62             | 7/10/**15**   |\n",
    "|        +       | 5       | 57             | 7/10/15   |\n",
    "|        +       | 10       | 57             | **2**/10/15   |\n",
    "|        -       | None       | 59            | 2/10/**15**   |\n",
    "|        -       | 2       | 60             | 2/5/7/**10**/15   |\n",
    "|        -       | 5       | 58             | **2**   |\n",
    "|        -       | 10       | 61             | **2**   |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9df5590c36242588aa2ec08b48d5460772f3434d8fd6d76e09f7949a0a7cd2ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
